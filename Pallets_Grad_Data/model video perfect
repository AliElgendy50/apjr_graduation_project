from roboflow import Roboflow
import supervision as sv
import cv2

rf = Roboflow(api_key="LlIKXYgtTmJZ2CUwv4Hl")
project = rf.workspace().project("pallet-5esjz")
model = project.version(1).model

# Open a video file or stream
video_capture = cv2.VideoCapture("pallets2.mp4")  # Or 0 for webcam stream

# Check if the video capture is open
if not video_capture.isOpened():
    print("Error: Unable to open video source.")
    exit()

while True:
    # Read a frame from the video
    ret, frame = video_capture.read()
    if not ret:
        print("Error: Unable to read frame.")
        break

    # Predict on the frame
    result = model.predict(frame, confidence=40, overlap=30).json()
    detections = sv.Detections.from_inference(result)
    labels = [item["class"] for item in result["predictions"]]

    # Annotate the frame
    label_annotator = sv.LabelAnnotator()
    bounding_box_annotator = sv.BoundingBoxAnnotator()

    annotated_frame = bounding_box_annotator.annotate(scene=frame, detections=detections)
    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)

    # Convert the annotated frame from BGR to RGB format
    annotated_frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)

    # Display the annotated frame using supervision's plot_image function
    sv.plot_image(image=annotated_frame_rgb, size=(16, 16))

    # Decision-making based on detected objects
    for detection in result["predictions"]:
        if detection["class"] == "pallet":
            # If a pallet is detected, take some action
            print("Pallet detected! Take action...")
            # Your decision-making logic here, such as controlling a robot or triggering an event

# Release the video capture and close OpenCV windows
video_capture.release()
cv2.destroyAllWindows()
